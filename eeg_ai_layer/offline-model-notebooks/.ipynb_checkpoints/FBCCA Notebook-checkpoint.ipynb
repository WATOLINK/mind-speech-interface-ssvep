{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ab2d339",
   "metadata": {},
   "source": [
    "# FBCCA OFFLINE ANALYSIS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43238eb",
   "metadata": {},
   "source": [
    "FBCCA applied to our data, this work is adapted from the work in the following repo: https://github.com/eugeneALU/CECNL_RealTimeBCI/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc97397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.signal import butter, filtfilt, iirnotch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35ce74c",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "96eee37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_eeg(csvname, flicker_freq):\n",
    "\n",
    "    # Establishing what flicker frequencies are present\n",
    "    flicker_freq_dict = dict()    \n",
    "\n",
    "    path = os.path.split(os.getcwd())[0] + '/data/' + csvname + '.csv'\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    #count value for zero cases\n",
    "    count = 0\n",
    "\n",
    "    # Adding row keys of relevant frequencies from dataframe \n",
    "    for i, freq_point in enumerate(df['Frequency']):\n",
    "        if not np.isnan(freq_point) and freq_point != 0: \n",
    "\n",
    "            \"\"\"\n",
    "            #zero case\n",
    "            if freq_point == 0 and count < (1 + num_stims):\n",
    "                count +=1\n",
    "\n",
    "            elif freq_point == 0 and count == (1 + num_stims):\n",
    "\n",
    "                if freq_point not in flicker_freq_dict.keys():\n",
    "                    flicker_freq_dict.update({freq_point: [i]})\n",
    "                else:\n",
    "                    flicker_freq_dict[freq_point].append(i)\n",
    "\n",
    "                count = 1\n",
    "            \"\"\"\n",
    "            #normal case  \n",
    "            if freq_point not in flicker_freq_dict.keys():\n",
    "                flicker_freq_dict.update({freq_point: [i]})\n",
    "            else:\n",
    "                flicker_freq_dict[freq_point].append(i)\n",
    "\n",
    "    flicker_freq = np.array(list(flicker_freq_dict.keys()))\n",
    "    flicker_freq.sort()\n",
    "\n",
    "    # Formatting the eeg data -> making the appropriate matrix\n",
    "    # Initializing the dimensions of the eeg matrix\n",
    "\n",
    "    num_classes = len(flicker_freq) \n",
    "    n_ch = 8 \n",
    "    total_trial_len = 1114 \n",
    "\n",
    "    #scales to number of trials in csv for each freq\n",
    "    num_trials = min(len(flicker_freq_dict[key]) for key in flicker_freq)\n",
    "\n",
    "    #instantiates eeg data in 4 dimensional np array\n",
    "    eeg = np.zeros((num_classes,n_ch,total_trial_len,num_trials))\n",
    "\n",
    "    # Assigning the correct values to the matrix/object\n",
    "\n",
    "    start_idx_list = []\n",
    "\n",
    "\n",
    "    #grabs start and endpoints for each frequency flash\n",
    "    for i, freq in enumerate(flicker_freq):\n",
    "        for j in range(num_trials):\n",
    "            start_idx = flicker_freq_dict[freq][j]\n",
    "            start_idx_list.append(start_idx)\n",
    "            end_idx = start_idx + total_trial_len\n",
    "\n",
    "            #shaves off timestamps and markers and does a transpose, we transpose it back and cast as a np array\n",
    "            eeg[i, :, :, j] = np.array(df.iloc[start_idx:end_idx, 1:9]).transpose((1,0))\n",
    "\n",
    "    return eeg, flicker_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "d7088de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer(data, duration, data_overlap):\n",
    "    '''\n",
    "    Returns segmented data based on the provided input window duration and overlap.\n",
    "    Args:\n",
    "        data (numpy.ndarray): array of samples. \n",
    "        duration (int): window length (number of samples).\n",
    "        data_overlap (int): number of samples of overlap.\n",
    "    Returns:\n",
    "        (numpy.ndarray): segmented data of shape (number_of_segments, duration).\n",
    "    '''\n",
    "    \n",
    "    number_segments = int(np.ceil((len(data) - data_overlap)/(duration - data_overlap)))\n",
    "    temp_buf = [data[i:i+duration] for i in range(0, len(data), (duration - int(data_overlap)))]\n",
    "    temp_buf[number_segments-1] = np.pad(temp_buf[number_segments-1],\n",
    "                                         (0, duration-temp_buf[number_segments-1].shape[0]),\n",
    "                                         'constant')\n",
    "    segmented_data = np.vstack(temp_buf[0:number_segments])\n",
    "    \n",
    "    return segmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "42ed67b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iir_notch_filter(data, f0, Q, fs):\n",
    "    '''\n",
    "    Returns notch filtered data for frequencies specified in the input.\n",
    "    Args:\n",
    "        data (numpy.ndarray): array of samples. \n",
    "        fi (float): frequency to eliminate (Hz).\n",
    "        fs (float): sampling rate (Hz).\n",
    "        Q (int): quality factor.\n",
    "    Returns:\n",
    "        (numpy.ndarray): data with powerline interference removed\n",
    "    '''\n",
    "    b, a = iirnotch(f0, Q, fs)\n",
    "    y = filtfilt(b, a, data)\n",
    "    #still need to filter harmonics\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "63a7916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_eeg(eeg, quality, sample_rate):\n",
    "    \n",
    "    num_classes = eeg.shape[0]\n",
    "    num_chan = eeg.shape[1]\n",
    "    total_trial_len = eeg.shape[2]\n",
    "    num_trials = eeg.shape[3]\n",
    "\n",
    "    #instantiate object to be sent to notch filter\n",
    "    filtered_data = np.zeros((eeg.shape[0], eeg.shape[1], total_trial_len, eeg.shape[3]))\n",
    "\n",
    "    \n",
    "    for target in range(0, num_classes):\n",
    "        for channel in range(0, num_chan):\n",
    "            for trial in range(0, num_trials):\n",
    "                \n",
    "                #data to be filtered\n",
    "                signal_to_filter = np.squeeze( eeg[target, channel, 0:total_trial_len, trial] )\n",
    "                \n",
    "                #call to notch filter\n",
    "                filtered_data[target, channel, :, trial] = iir_notch_filter(signal_to_filter, \n",
    "                                                                    60, quality,\n",
    "                                                                    sample_rate)\n",
    "                \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "e5fa27fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterbank(eeg, fs, idx_fb):    \n",
    "    if idx_fb == None:\n",
    "        warnings.warn('stats:filterbank:MissingInput '\\\n",
    "                      +'Missing filter index. Default value (idx_fb = 0) will be used.')\n",
    "        idx_fb = 0\n",
    "    elif (idx_fb < 0 or 9 < idx_fb):\n",
    "        raise ValueError('stats:filterbank:InvalidInput '\\\n",
    "                          +'The number of sub-bands must be 0 <= idx_fb <= 9.')\n",
    "            \n",
    "    if (len(eeg.shape)==2):\n",
    "        num_chans = eeg.shape[0]\n",
    "        num_trials = 1\n",
    "    else:\n",
    "        num_chans, _, num_trials = eeg.shape\n",
    "    \n",
    "    # Nyquist Frequency = Fs/2N\n",
    "    Nq = fs/2\n",
    "    \n",
    "    passband = [6, 14, 22, 30, 38, 46, 54, 62, 70, 78]\n",
    "    stopband = [4, 10, 16, 24, 32, 40, 48, 56, 64, 72]\n",
    "    Wp = [passband[idx_fb]/Nq, 90/Nq]\n",
    "    Ws = [stopband[idx_fb]/Nq, 100/Nq]\n",
    "    [N, Wn] = scipy.signal.cheb1ord(Wp, Ws, 3, 40) # band pass filter StopBand=[Ws(1)~Ws(2)] PassBand=[Wp(1)~Wp(2)]\n",
    "    [B, A] = scipy.signal.cheby1(N, 0.5, Wn, 'bandpass') # Wn passband edge frequency\n",
    "    \n",
    "    y = np.zeros(eeg.shape)\n",
    "    if (num_trials == 1):\n",
    "        for ch_i in range(num_chans):\n",
    "            #apply filter, zero phass filtering by applying a linear filter twice, once forward and once backwards.\n",
    "            # to match matlab result we need to change padding length\n",
    "            y[ch_i, :] = scipy.signal.filtfilt(B, A, eeg[ch_i, :], padtype = 'odd', padlen=3*(max(len(B),len(A))-1))\n",
    "        \n",
    "    else:\n",
    "        for trial_i in range(num_trials):\n",
    "            for ch_i in range(num_chans):\n",
    "                y[ch_i, :, trial_i] = scipy.signal.filtfilt(B, A, eeg[ch_i, :, trial_i], padtype = 'odd', padlen=3*(max(len(B),len(A))-1))\n",
    "           \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "c75e3628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cca_reference(list_freqs, fs, num_smpls, num_harms=3):\n",
    "    \n",
    "    num_freqs = len(list_freqs)\n",
    "    tidx = np.arange(1,num_smpls+1)/fs #time index\n",
    "    \n",
    "    y_ref = np.zeros((num_freqs, 2*num_harms, num_smpls))\n",
    "    for freq_i in range(num_freqs):\n",
    "        tmp = []\n",
    "        for harm_i in range(1,num_harms+1):\n",
    "            stim_freq = list_freqs[freq_i]  #in HZ\n",
    "            # Sin and Cos\n",
    "            tmp.extend([np.sin(2*np.pi*tidx*harm_i*stim_freq),\n",
    "                       np.cos(2*np.pi*tidx*harm_i*stim_freq)])\n",
    "        y_ref[freq_i] = tmp # 2*num_harms because include both sin and cos\n",
    "    \n",
    "    return y_ref\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "38678231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbcca(eeg, list_freqs, fs, num_harms, num_fbs):\n",
    "    \n",
    "    fb_coefs = np.power(np.arange(1,num_fbs+1),(-1.25)) + 0.25\n",
    "    \n",
    "    num_targs, num_chan, num_smpls, num_trials = eeg.shape  \n",
    "    \n",
    "    y_ref = cca_reference(list_freqs, fs, num_smpls, num_harms)\n",
    "    \n",
    "    cca = CCA(n_components=1) #initilize CCA\n",
    "    \n",
    "    # result matrix\n",
    "    r = np.zeros((num_fbs,num_targs))\n",
    "    results = np.zeros((num_targs, num_trials))\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "\n",
    "      for targ_i in range(num_targs):\n",
    "          test_tmp = np.squeeze(eeg[targ_i, :, :, trial])  #deal with one target a time\n",
    "          \n",
    "          for fb_i in range(num_fbs):  #filter bank number, deal with different filter bank\n",
    "              testdata = filterbank(test_tmp, fs, fb_i)  #data after filtering\n",
    "              \n",
    "              for class_i in range(num_targs):\n",
    "                  refdata = np.squeeze(y_ref[class_i, :, :])   #pick corresponding freq target reference signal\n",
    "                  test_C, ref_C = cca.fit_transform(testdata.T, refdata.T)\n",
    "                  # len(row) = len(observation), len(column) = variables of each observation\n",
    "                  # number of rows should be the same, so need transpose here\n",
    "                  # output is the highest correlation linear combination of two sets\n",
    "                  r_tmp, _ = pearsonr(np.squeeze(test_C), np.squeeze(ref_C)) #return r and p_value, use np.squeeze to adapt the API \n",
    "                  r[fb_i, class_i] = r_tmp\n",
    "                 \n",
    "          rho = np.dot(fb_coefs, r)  #weighted sum of r from all different filter banks' result\n",
    "          tau = np.argmax(rho)  #get maximum from the target as the final predict (get the index)\n",
    "          results[targ_i, trial] = tau #index indicate the maximum(most possible) target\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73669194",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "7a2dc5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up some completely fixed parameters\n",
    "FFT_PARAMS = {\n",
    "    'resolution': 0.2930,\n",
    "    'start_frequency': 0.0,\n",
    "    'end_frequency': 35.0,\n",
    "    'sampling_rate': 250\n",
    "}\n",
    "\n",
    "flicker_freq = []\n",
    "\n",
    "#change this depending on the number of stimuli in the data\n",
    "num_stims = 4\n",
    "\n",
    "#harmonics analyzed\n",
    "num_harms=3\n",
    "#filterbanks produced\n",
    "num_fbs=5 \n",
    "\n",
    "#quality of notch\n",
    "Q = 100\n",
    "\n",
    "sample_rate = FFT_PARAMS['sampling_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e6ffef",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "36e9ccdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174_2022_159090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 8, 1114, 15)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REPLACE CSV NAME WITH CSV OF INTEREST\n",
    "\n",
    "#csvnames = ['174_2022_159090', '174_2022_445753', '174_2022_538724'] #Bryan\n",
    "\n",
    "#csvnames = ['174_2022_040508', '174_2022_123780', '174_2022_729377'] #Chris\n",
    "\n",
    "#csvnames = ['173_2022_515272'] #Avery\n",
    "\n",
    "\n",
    "csvnames = ['174_2022_159090', '174_2022_445753', '174_2022_538724']\n",
    "\n",
    "print(csvnames[0])\n",
    "eeg1, flicker_freq1 = ingest_eeg(str(csvnames[0]), flicker_freq)\n",
    "eeg2, flicker_freq2 = ingest_eeg(str(csvnames[1]), flicker_freq)\n",
    "eeg3, flicker_freq3 = ingest_eeg(str(csvnames[2]), flicker_freq)\n",
    "\n",
    "eeg = np.concatenate((eeg1, eeg2, eeg3), axis=3)\n",
    "\n",
    "#combines epoched data across all csvs along trials axis\n",
    "eeg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "b0860b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.25, 11.75, 12.75, 14.75]\n",
      "[10.25, 11.75, 12.75, 14.75]\n",
      "[10.25, 11.75, 12.75, 14.75]\n"
     ]
    }
   ],
   "source": [
    "#validate that data is sorted properly before concatenation\n",
    "list_freq1 = list(flicker_freq1)\n",
    "list_freq2 = list(flicker_freq1)\n",
    "list_freq3 = list(flicker_freq1)\n",
    "print(list_freq1) \n",
    "print(list_freq2) \n",
    "print(list_freq3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5edac1",
   "metadata": {},
   "source": [
    "## Powerline Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "868f5913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8, 1114, 15)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wrapper function for EEG data filtering with 4th order notch\n",
    "filtered_data = get_filtered_eeg(eeg, Q, sample_rate)\n",
    "filtered_data.shape #(classes, channels, # of samples, # of trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843cc359",
   "metadata": {},
   "source": [
    "## FBCCA Execution and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "a249f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fbcca(filtered_data, list_freq1, sample_rate, num_harms, num_fbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "a766da70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [3. 3. 3. 3. 0. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 15)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "example of a perfect result for a 5 trial dataset:\n",
    "\n",
    "[[0. 0. 0. 0. 0.]\n",
    " [1. 1. 1. 1. 1.]\n",
    " [2. 2. 2. 2. 2.]\n",
    " [3. 3. 3. 3. 3.]]\n",
    " \n",
    "\"\"\"\n",
    "print(results)\n",
    "results.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
